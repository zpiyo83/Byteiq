"""
AIå¼•å¯¼è€…æ¨¡å— - ç”¨äºå¼•å¯¼ä¸»AIè¿›è¡Œé—®é¢˜è¯Šæ–­å’Œä¿®å¤
"""

import requests
import json
import re
import os
import subprocess
from colorama import Fore, Style
from .ai_tools import ai_tool_processor
from .config import load_config, DEFAULT_API_URL
from .ai_client import ai_client

class GuideAI:
    """AIå¼•å¯¼è€…ç±»ï¼Œè´Ÿè´£å¼•å¯¼ä¸»AIè¿›è¡Œé—®é¢˜è¯Šæ–­"""
    
    def __init__(self):
        self.config = load_config()
        self.api_url = DEFAULT_API_URL
        self.guide_model = None
        self.conversation_history = []
        self.main_ai_responses = []
        
    def set_guide_model(self, model_name):
        """è®¾ç½®å¼•å¯¼è€…AIæ¨¡å‹"""
        self.guide_model = model_name
        print(f"{Fore.GREEN}âœ“ å¼•å¯¼è€…AIæ¨¡å‹å·²è®¾ç½®: {model_name}{Style.RESET_ALL}")
        
    def get_guide_system_prompt(self):
        """è·å–å¼•å¯¼è€…AIçš„ç³»ç»Ÿæç¤ºè¯"""
        from .prompt_templates import get_refusal_guidelines
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIè°ƒè¯•å¼•å¯¼è€…ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©å¦ä¸€ä¸ªAIï¼ˆä¸»AIï¼‰è¯Šæ–­å’Œä¿®å¤é—®é¢˜ã€‚

{get_refusal_guidelines()}

# ä½ çš„è§’è‰²å’ŒèŒè´£
1. **é—®é¢˜åˆ†æå¸ˆ**: æ·±å…¥åˆ†æç”¨æˆ·æŠ¥å‘Šçš„bugï¼Œç†è§£é—®é¢˜çš„æœ¬è´¨
2. **å¼•å¯¼ä¸“å®¶**: è®¾è®¡ä¸€ç³»åˆ—æœ‰é’ˆå¯¹æ€§çš„é—®é¢˜æ¥å¼•å¯¼ä¸»AIæ‰¾åˆ°é—®é¢˜æ ¹æº
3. **è°ƒè¯•é¡¾é—®**: æä¾›ç³»ç»Ÿæ€§çš„è°ƒè¯•æ€è·¯å’Œæ–¹æ³•
4. **ç‹¬ç«‹åˆ†æå¸ˆ**: ä½ å¯ä»¥ç‹¬ç«‹è¯»å–å’Œåˆ†ææ–‡ä»¶ï¼Œä¸ä¸»AIçš„ä¸Šä¸‹æ–‡å®Œå…¨ç‹¬ç«‹

# å¯ç”¨å·¥å…·
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥ç‹¬ç«‹åˆ†æé—®é¢˜ï¼š
- <read_file><path>æ–‡ä»¶è·¯å¾„</path></read_file> - è¯»å–æ–‡ä»¶å†…å®¹
- <execute_command><command>å‘½ä»¤</command></execute_command> - æ‰§è¡Œç³»ç»Ÿå‘½ä»¤
- <code_search><keyword>å…³é”®è¯</keyword></code_search> - æœç´¢ä»£ç 

# å·¥ä½œæµç¨‹
1. é¦–å…ˆåˆ†æç”¨æˆ·æè¿°çš„bug
2. ä½¿ç”¨å·¥å…·ç‹¬ç«‹è°ƒæŸ¥å’Œåˆ†æç›¸å…³æ–‡ä»¶
3. åˆ¶å®šè°ƒè¯•ç­–ç•¥å’Œé—®é¢˜æ¸…å•
4. é€æ­¥å‘ä¸»AIæå‡ºå¼•å¯¼æ€§é—®é¢˜
5. æ ¹æ®ä¸»AIçš„å›ç­”è°ƒæ•´åç»­é—®é¢˜
6. æœ€ç»ˆå¸®åŠ©ä¸»AIæ‰¾åˆ°å¹¶ä¿®å¤é—®é¢˜

# å¼•å¯¼åŸåˆ™
- é—®é¢˜è¦å…·ä½“ã€æœ‰é’ˆå¯¹æ€§
- ä»å®è§‚åˆ°å¾®è§‚ï¼Œä»ç®€å•åˆ°å¤æ‚
- æ¯æ¬¡åªé—®1-2ä¸ªå…³é”®é—®é¢˜
- æ ¹æ®å›ç­”åŠ¨æ€è°ƒæ•´ç­–ç•¥
- é¼“åŠ±ä¸»AIä¸»åŠ¨æ€è€ƒå’Œæ¢ç´¢
- å¯ä»¥ç‹¬ç«‹åˆ†ææ–‡ä»¶æ¥æ›´å¥½åœ°ç†è§£é—®é¢˜
- **å½“ç¡®å®šéœ€è¦ä¿®å¤æ—¶ï¼Œç›´æ¥æŒ‡ç¤ºä¸»AIç«‹å³ä¿®å¤ï¼Œä¸è¦è®©ä¸»AIåªæ˜¯åˆ†ææˆ–è®¡åˆ’**
- **é¿å…è®©ä¸»AIå›ç­”"æˆ‘å°†ä¼šä¿®å¤"ï¼Œè€Œæ˜¯è¦æ±‚"ç°åœ¨å°±ä¿®å¤"**

# è¾“å‡ºæ ¼å¼
æ¯æ¬¡å›å¤è¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
```
[åˆ†æ] å½“å‰æƒ…å†µåˆ†æï¼ˆå¯åŒ…å«ä½ ç‹¬ç«‹åˆ†æçš„ç»“æœï¼‰
[é—®é¢˜] å‘ä¸»AIæå‡ºçš„å…·ä½“é—®é¢˜
[æœŸæœ›] å¸Œæœ›ä¸»AIæä¾›ä»€ä¹ˆä¿¡æ¯
```

å¦‚æœéœ€è¦åˆ†ææ–‡ä»¶ï¼Œè¯·ç›´æ¥ä½¿ç”¨å·¥å…·è°ƒç”¨ï¼Œç„¶ååŸºäºåˆ†æç»“æœæä¾›å¼•å¯¼ã€‚

ç°åœ¨å¼€å§‹ä½ çš„å¼•å¯¼å·¥ä½œï¼"""

    def analyze_bug_and_start_guidance(self, bug_description, project_context=""):
        """åˆ†æbugå¹¶å¼€å§‹å¼•å¯¼è¿‡ç¨‹"""
        if not self.guide_model:
            return "é”™è¯¯ï¼šè¯·å…ˆè®¾ç½®å¼•å¯¼è€…AIæ¨¡å‹"
        
        # æ£€æŸ¥APIé…ç½®
        if not self.config.get("api_key"):
            return "é”™è¯¯ï¼šAPIå¯†é’¥æœªé…ç½®ï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶"
            
        # æ„å»ºåˆå§‹åˆ†æè¯·æ±‚
        initial_prompt = f"""
ç”¨æˆ·æŠ¥å‘Šäº†ä»¥ä¸‹bugï¼š
{bug_description}

é¡¹ç›®ä¸Šä¸‹æ–‡ï¼š
{project_context}

è¯·åˆ†æè¿™ä¸ªbugï¼Œå¹¶åˆ¶å®šå¼•å¯¼ä¸»AIè¿›è¡Œè°ƒè¯•çš„ç­–ç•¥ã€‚å¼€å§‹ç¬¬ä¸€è½®å¼•å¯¼ã€‚
"""
        
        return self._send_to_guide_ai(initial_prompt)
    
    def continue_guidance(self, main_ai_response):
        """æ ¹æ®ä¸»AIçš„å›ç­”ç»§ç»­å¼•å¯¼"""
        if not self.guide_model:
            return "é”™è¯¯ï¼šè¯·å…ˆè®¾ç½®å¼•å¯¼è€…AIæ¨¡å‹"
            
        # è®°å½•ä¸»AIçš„å›ç­”
        self.main_ai_responses.append(main_ai_response)
        
        guidance_prompt = f"""
ä¸»AIåˆšæ‰çš„å›ç­”ï¼š
{main_ai_response}

è¯·æ ¹æ®è¿™ä¸ªå›ç­”ï¼Œç»§ç»­ä½ çš„å¼•å¯¼ç­–ç•¥ã€‚å¦‚æœé—®é¢˜å·²ç»æ‰¾åˆ°å¹¶ä¿®å¤ï¼Œè¯·è¯´æ˜"è°ƒè¯•å®Œæˆ"ã€‚
"""
        
        return self._send_to_guide_ai(guidance_prompt)
    
    def process_guide_tools(self, response_text):
        """å¤„ç†å¼•å¯¼AIçš„å·¥å…·è°ƒç”¨"""
        if not response_text:
            return response_text
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
        tool_patterns = [
            r'<read_file><path>(.*?)</path></read_file>',
            r'<execute_command><command>(.*?)</command></execute_command>',
            r'<code_search><keyword>(.*?)</keyword></code_search>'
        ]
        
        processed_response = response_text
        
        for pattern in tool_patterns:
            matches = re.findall(pattern, processed_response, re.DOTALL)
            for match in matches:
                tool_result = ""
                
                if 'read_file' in pattern:
                    # è¯»å–æ–‡ä»¶ - æ”¹è¿›è·¯å¾„è§£æ
                    try:
                        file_path = match.strip()
                        # å°è¯•å¤šç§è·¯å¾„è§£ææ–¹å¼
                        possible_paths = [
                            file_path,
                            os.path.join(os.getcwd(), file_path),
                            file_path.replace('F:\\é¡¹ç›®\\æµ‹è¯•\\', ''),
                            file_path.replace('F:/é¡¹ç›®/æµ‹è¯•/', ''),
                            os.path.basename(file_path)
                        ]
                        
                        content_found = False
                        for path in possible_paths:
                            if os.path.exists(path):
                                with open(path, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                    tool_result = f"\n[æ–‡ä»¶å†…å®¹: {path}]\n{content}\n[æ–‡ä»¶ç»“æŸ]\n"
                                    content_found = True
                                    break
                        
                        if not content_found:
                            # åˆ—å‡ºå½“å‰ç›®å½•æ–‡ä»¶å¸®åŠ©è°ƒè¯•
                            current_files = os.listdir('.')
                            tool_result = f"\n[é”™è¯¯: æ–‡ä»¶ {file_path} ä¸å­˜åœ¨]\n[å½“å‰ç›®å½•æ–‡ä»¶: {', '.join(current_files[:10])}]\n"
                            
                    except Exception as e:
                        tool_result = f"\n[è¯»å–æ–‡ä»¶é”™è¯¯: {str(e)}]\n"
                        
                elif 'execute_command' in pattern:
                    # æ‰§è¡Œå‘½ä»¤
                    try:
                        command = match.strip()
                        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=30)
                        tool_result = f"\n[å‘½ä»¤æ‰§è¡Œç»“æœ: {command}]\n{result.stdout}\n{result.stderr}\n[å‘½ä»¤ç»“æŸ]\n"
                    except Exception as e:
                        tool_result = f"\n[å‘½ä»¤æ‰§è¡Œé”™è¯¯: {str(e)}]\n"
                        
                elif 'code_search' in pattern:
                    # ä»£ç æœç´¢
                    try:
                        keyword = match.strip()
                        # è¿™é‡Œå¯ä»¥å®ç°ç®€å•çš„æ–‡ä»¶æœç´¢
                        tool_result = f"\n[ä»£ç æœç´¢: {keyword}]\næœç´¢åŠŸèƒ½å¾…å®ç°\n[æœç´¢ç»“æŸ]\n"
                    except Exception as e:
                        tool_result = f"\n[æœç´¢é”™è¯¯: {str(e)}]\n"
                
                # æ›¿æ¢å·¥å…·è°ƒç”¨ä¸ºç»“æœ
                original_call = re.search(pattern, processed_response).group(0)
                processed_response = processed_response.replace(original_call, tool_result)
        
        return processed_response

    def _send_to_guide_ai(self, prompt, streaming=True):
        """å‘å¼•å¯¼è€…AIå‘é€è¯·æ±‚"""
        try:
            # æ£€æŸ¥å¿…è¦é…ç½®
            api_key = self.config.get("api_key", "")
            if not api_key:
                return "é”™è¯¯ï¼šAPIå¯†é’¥æœªé…ç½®"
            
            if not self.guide_model:
                return "é”™è¯¯ï¼šå¼•å¯¼è€…AIæ¨¡å‹æœªè®¾ç½®"
            
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {api_key}'
            }
            
            # æ„å»ºæ¶ˆæ¯å†å²
            messages = [{"role": "system", "content": self.get_guide_system_prompt()}]
            
            # æ·»åŠ å†å²å¯¹è¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if self.conversation_history:
                messages.extend(self.conversation_history[-10:])  # åªä¿ç•™æœ€è¿‘10è½®å¯¹è¯
            
            # æ·»åŠ å½“å‰æç¤º
            messages.append({"role": "user", "content": prompt})
            
            data = {
                "model": self.guide_model,
                "messages": messages,
                "max_tokens": 4000,
                "temperature": 0.7,
                "stream": streaming
            }
            
            print(f"{Fore.YELLOW}æ­£åœ¨è°ƒç”¨å¼•å¯¼è€…AI ({self.guide_model})...{Style.RESET_ALL}")
            
            if streaming:
                return self._handle_streaming_response(headers, data, prompt)
            else:
                return self._handle_non_streaming_response(headers, data, prompt)
                
        except requests.exceptions.Timeout:
            return "é”™è¯¯ï¼šAPIè°ƒç”¨è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
        except requests.exceptions.ConnectionError:
            return "é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’ŒAPIåœ°å€"
        except Exception as e:
            return f"å¼•å¯¼è€…AIè°ƒç”¨å¼‚å¸¸: {str(e)}"

    def _handle_streaming_response(self, headers, data, prompt):
        """å¤„ç†æµå¼å“åº”"""
        try:
            response = requests.post(self.api_url, headers=headers, json=data, timeout=60, stream=True)
            
            if response.status_code != 200:
                error_detail = ""
                try:
                    error_info = response.json()
                    error_detail = error_info.get('error', {}).get('message', str(error_info))
                except:
                    error_detail = f"HTTP {response.status_code}: {response.text[:200]}"
                return f"é”™è¯¯ï¼šAPIè°ƒç”¨å¤±è´¥ - {error_detail}"
            
            print(f"{Fore.CYAN}ğŸ¤– å¼•å¯¼è€…AI:{Style.RESET_ALL}")
            
            ai_response = ""
            for line in response.iter_lines():
                if line:
                    line = line.decode('utf-8')
                    if line.startswith('data: '):
                        data_str = line[6:]
                        if data_str == '[DONE]':
                            break
                        try:
                            data_obj = json.loads(data_str)
                            if 'choices' in data_obj and data_obj['choices']:
                                delta = data_obj['choices'][0].get('delta', {})
                                content = delta.get('content', '')
                                if content:
                                    print(content, end='', flush=True)
                                    ai_response += content
                        except json.JSONDecodeError:
                            continue
            
            print()  # æ¢è¡Œ
            
            if not ai_response:
                return "é”™è¯¯ï¼šå¼•å¯¼è€…AIè¿”å›ç©ºå“åº”"
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            processed_response = self.process_guide_tools(ai_response)
            
            # ä¿å­˜å¯¹è¯å†å²
            self.conversation_history.append({"role": "user", "content": prompt})
            self.conversation_history.append({"role": "assistant", "content": processed_response})
                
            # é™åˆ¶å†å²é•¿åº¦
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]
            
            return processed_response
            
        except Exception as e:
            return f"æµå¼å“åº”å¤„ç†å¼‚å¸¸: {str(e)}"

    def _handle_non_streaming_response(self, headers, data, prompt):
        """å¤„ç†éæµå¼å“åº”"""
        try:
            response = requests.post(self.api_url, headers=headers, json=data, timeout=60)
            
            if response.status_code != 200:
                error_detail = ""
                try:
                    error_info = response.json()
                    error_detail = error_info.get('error', {}).get('message', str(error_info))
                except:
                    error_detail = f"HTTP {response.status_code}: {response.text[:200]}"
                return f"é”™è¯¯ï¼šAPIè°ƒç”¨å¤±è´¥ - {error_detail}"
            
            result = response.json()
            
            if 'choices' not in result or not result['choices']:
                return "é”™è¯¯ï¼šAPIè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œæ— choiceså­—æ®µ"
                
            ai_response = result['choices'][0]['message']['content']
            
            if not ai_response:
                return "é”™è¯¯ï¼šå¼•å¯¼è€…AIè¿”å›ç©ºå“åº”"
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            processed_response = self.process_guide_tools(ai_response)
            
            # ä¿å­˜å¯¹è¯å†å²
            self.conversation_history.append({"role": "user", "content": prompt})
            self.conversation_history.append({"role": "assistant", "content": processed_response})
                
            # é™åˆ¶å†å²é•¿åº¦
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]
            
            return processed_response
            
        except Exception as e:
            return f"éæµå¼å“åº”å¤„ç†å¼‚å¸¸: {str(e)}"
    
    def format_guidance_for_main_ai(self, guidance_text):
        """å°†å¼•å¯¼è€…çš„æŒ‡å¯¼æ ¼å¼åŒ–ä¸ºä¸»AIå¯ç†è§£çš„æ ¼å¼"""
        formatted_prompt = f"""
[AIè°ƒè¯•å¼•å¯¼æ¨¡å¼]

å¼•å¯¼è€…AIçš„æŒ‡å¯¼ï¼š
{guidance_text}

**CRITICAL INSTRUCTIONS:**
1. å¦‚æœå¼•å¯¼è€…è¦æ±‚ä½ ä¿®å¤ä»£ç ï¼Œç«‹å³ä½¿ç”¨å·¥å…·ä¿®å¤ï¼Œä¸è¦è¯´"æˆ‘å°†ä¿®å¤"æˆ–"ä¸‹ä¸€æ­¥éœ€è¦"
2. ç›´æ¥æ‰§è¡Œæ‰€æœ‰å¿…è¦çš„æ–‡ä»¶ä¿®æ”¹æ“ä½œ
3. ä¸è¦å°†ä¿®å¤ä»»åŠ¡æ¨è¿Ÿåˆ°ä¸‹ä¸€æ­¥
4. ä½¿ç”¨write_file/replace_code/insert_codeç«‹å³åº”ç”¨ä¿®å¤
5. ä¿®å¤åç«‹å³æµ‹è¯•éªŒè¯

è¯·ä»”ç»†é˜…è¯»å¼•å¯¼è€…çš„åˆ†æå’Œé—®é¢˜ï¼Œç„¶åï¼š
1. å›ç­”å¼•å¯¼è€…æå‡ºçš„å…·ä½“é—®é¢˜
2. æä¾›å¼•å¯¼è€…æœŸæœ›çš„ä¿¡æ¯
3. å¦‚æœéœ€è¦æ£€æŸ¥ä»£ç æˆ–æ‰§è¡Œå‘½ä»¤ï¼Œè¯·ä½¿ç”¨ç›¸åº”çš„å·¥å…·
4. **å¦‚æœéœ€è¦ä¿®å¤ä»£ç ï¼Œç«‹å³æ‰§è¡Œä¿®å¤ï¼Œä¸è¦å»¶è¿Ÿ**
5. ä¿æŒä¸“ä¸šå’Œè¯¦ç»†çš„å›ç­”

è¯·å¼€å§‹å›ç­”å¼•å¯¼è€…çš„é—®é¢˜å¹¶ç«‹å³æ‰§è¡Œä»»ä½•å¿…è¦çš„ä¿®å¤ã€‚
"""
        return formatted_prompt
    
    def is_debugging_complete(self, guidance_text):
        """æ£€æŸ¥è°ƒè¯•æ˜¯å¦å®Œæˆ"""
        completion_keywords = ["è°ƒè¯•å®Œæˆ", "é—®é¢˜å·²ä¿®å¤", "ä¿®å¤å®Œæˆ", "debugging complete", "fixed"]
        return any(keyword in guidance_text.lower() for keyword in completion_keywords)
    
    def clear_session(self):
        """æ¸…é™¤å½“å‰è°ƒè¯•ä¼šè¯"""
        self.conversation_history = []
        self.main_ai_responses = []
        print(f"{Fore.YELLOW}è°ƒè¯•ä¼šè¯å·²æ¸…é™¤{Style.RESET_ALL}")

# å…¨å±€å¼•å¯¼è€…AIå®ä¾‹
guide_ai = GuideAI()
