"""
é¡¹ç›®åˆ†æå™¨ - åˆ†æé¡¹ç›®ç»“æ„å¹¶ç”ŸæˆBYTEIQ.mdé…ç½®æ–‡ä»¶
"""

import os
import json
from pathlib import Path
from typing import Dict, List, Any, Optional
from colorama import Fore, Style

class ProjectAnalyzer:
    """é¡¹ç›®åˆ†æå™¨"""
    
    def __init__(self, project_path: str = "."):
        self.project_path = Path(project_path).resolve()
        self.analysis_result = {}
        
    def analyze_project(self) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®å¹¶è¿”å›åˆ†æç»“æœ"""
        print(f"{Fore.CYAN}ğŸ” å¼€å§‹åˆ†æé¡¹ç›®: {self.project_path}{Style.RESET_ALL}")
        
        self.analysis_result = {
            "project_info": self._analyze_project_info(),
            "file_structure": self._analyze_file_structure(),
            "dependencies": self._analyze_dependencies(),
            "code_features": self._analyze_code_features(),
            "project_type": self._detect_project_type(),
            "tech_stack": self._detect_tech_stack(),
        }
        
        print(f"{Fore.GREEN}âœ“ é¡¹ç›®åˆ†æå®Œæˆ{Style.RESET_ALL}")
        return self.analysis_result
    
    def _analyze_project_info(self) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®åŸºæœ¬ä¿¡æ¯"""
        info = {
            "name": self.project_path.name,
            "path": str(self.project_path),
            "size": self._calculate_project_size(),
        }
        
        # æŸ¥æ‰¾READMEæ–‡ä»¶
        readme_files = list(self.project_path.glob("README*"))
        if readme_files:
            info["readme"] = str(readme_files[0])
            
        return info
    
    def _analyze_file_structure(self) -> Dict[str, Any]:
        """åˆ†ææ–‡ä»¶ç»“æ„"""
        structure = {
            "total_files": 0,
            "directories": [],
            "file_types": {},
            "main_files": [],
        }
        
        # å¿½ç•¥çš„ç›®å½•
        ignore_dirs = {'.git', '__pycache__', '.vscode', '.idea', 'node_modules', '.env'}
        
        for root, dirs, files in os.walk(self.project_path):
            # è¿‡æ»¤å¿½ç•¥çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in ignore_dirs]
            
            rel_root = os.path.relpath(root, self.project_path)
            if rel_root != '.':
                structure["directories"].append(rel_root)
            
            for file in files:
                if file.startswith('.'):
                    continue
                    
                structure["total_files"] += 1
                
                # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
                ext = Path(file).suffix.lower()
                if ext:
                    structure["file_types"][ext] = structure["file_types"].get(ext, 0) + 1
                
                # è¯†åˆ«ä¸»è¦æ–‡ä»¶
                if file.lower() in ['main.py', 'app.py', 'index.py', 'run.py', '__init__.py']:
                    structure["main_files"].append(os.path.join(rel_root, file))
        
        return structure
    
    def _analyze_dependencies(self) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®ä¾èµ–"""
        deps = {
            "python": {},
            "javascript": {},
            "other": {}
        }
        
        # Pythonä¾èµ–
        requirements_files = ['requirements.txt', 'pyproject.toml', 'setup.py', 'Pipfile']
        for req_file in requirements_files:
            req_path = self.project_path / req_file
            if req_path.exists():
                deps["python"][req_file] = self._parse_python_deps(req_path)
        
        # JavaScriptä¾èµ–
        package_json = self.project_path / 'package.json'
        if package_json.exists():
            try:
                with open(package_json, 'r', encoding='utf-8') as f:
                    package_data = json.load(f)
                    deps["javascript"]["package.json"] = {
                        "dependencies": package_data.get("dependencies", {}),
                        "devDependencies": package_data.get("devDependencies", {})
                    }
            except Exception:
                pass
        
        return deps
    
    def _parse_python_deps(self, file_path: Path) -> List[str]:
        """è§£æPythonä¾èµ–æ–‡ä»¶"""
        deps = []
        try:
            if file_path.name == 'requirements.txt':
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            deps.append(line.split('==')[0].split('>=')[0].split('<=')[0])
            elif file_path.name == 'pyproject.toml':
                # ç®€å•è§£æpyproject.toml
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'dependencies' in content:
                        deps.append("pyproject.tomlé…ç½®")
        except Exception:
            pass
        return deps
    
    def _analyze_code_features(self) -> Dict[str, Any]:
        """åˆ†æä»£ç ç‰¹å¾"""
        features = {
            "languages": set(),
            "frameworks": set(),
            "patterns": set(),
            "imports": set(),
        }
        
        # åˆ†æPythonæ–‡ä»¶
        for py_file in self.project_path.rglob("*.py"):
            if '__pycache__' in str(py_file):
                continue
                
            features["languages"].add("Python")
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    self._analyze_python_code(content, features)
            except Exception:
                pass
        
        # åˆ†æå…¶ä»–æ–‡ä»¶ç±»å‹
        for js_file in self.project_path.rglob("*.js"):
            features["languages"].add("JavaScript")
        
        for ts_file in self.project_path.rglob("*.ts"):
            features["languages"].add("TypeScript")
            
        for html_file in self.project_path.rglob("*.html"):
            features["languages"].add("HTML")
            
        for css_file in self.project_path.rglob("*.css"):
            features["languages"].add("CSS")
        
        # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
        for key in features:
            if isinstance(features[key], set):
                features[key] = list(features[key])
        
        return features
    
    def _analyze_python_code(self, content: str, features: Dict[str, Any]):
        """åˆ†æPythonä»£ç ç‰¹å¾"""
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            
            # åˆ†æå¯¼å…¥
            if line.startswith('import ') or line.startswith('from '):
                if 'flask' in line.lower():
                    features["frameworks"].add("Flask")
                elif 'django' in line.lower():
                    features["frameworks"].add("Django")
                elif 'fastapi' in line.lower():
                    features["frameworks"].add("FastAPI")
                elif 'streamlit' in line.lower():
                    features["frameworks"].add("Streamlit")
                elif 'tkinter' in line.lower():
                    features["frameworks"].add("Tkinter")
                elif 'colorama' in line.lower():
                    features["imports"].add("colorama")
                elif 'requests' in line.lower():
                    features["imports"].add("requests")
                elif 'numpy' in line.lower():
                    features["imports"].add("numpy")
                elif 'pandas' in line.lower():
                    features["imports"].add("pandas")
            
            # åˆ†ææ¨¡å¼
            if 'class ' in line and ':' in line:
                features["patterns"].add("é¢å‘å¯¹è±¡ç¼–ç¨‹")
            if 'async def' in line:
                features["patterns"].add("å¼‚æ­¥ç¼–ç¨‹")
            if 'if __name__ == "__main__"' in line:
                features["patterns"].add("è„šæœ¬æ¨¡å¼")
    
    def _detect_project_type(self) -> str:
        """æ£€æµ‹é¡¹ç›®ç±»å‹"""
        # æ£€æŸ¥ç‰¹å®šæ–‡ä»¶å­˜åœ¨
        if (self.project_path / 'manage.py').exists():
            return "Django Webåº”ç”¨"
        elif (self.project_path / 'app.py').exists() or any(self.project_path.rglob("*flask*")):
            return "Flask Webåº”ç”¨"
        elif (self.project_path / 'package.json').exists():
            return "Node.jsåº”ç”¨"
        elif (self.project_path / 'requirements.txt').exists() or (self.project_path / 'pyproject.toml').exists():
            return "Pythonåº”ç”¨"
        elif any(self.project_path.rglob("*.py")):
            return "Pythoné¡¹ç›®"
        elif any(self.project_path.rglob("*.js")):
            return "JavaScripté¡¹ç›®"
        else:
            return "é€šç”¨é¡¹ç›®"
    
    def _detect_tech_stack(self) -> List[str]:
        """æ£€æµ‹æŠ€æœ¯æ ˆ"""
        stack = []
        
        # Pythonç›¸å…³
        if any(self.project_path.rglob("*.py")):
            stack.append("Python")
            
        # Webç›¸å…³
        if any(self.project_path.rglob("*.html")):
            stack.append("HTML")
        if any(self.project_path.rglob("*.css")):
            stack.append("CSS")
        if any(self.project_path.rglob("*.js")):
            stack.append("JavaScript")
            
        # æ•°æ®åº“
        if any(self.project_path.rglob("*.sql")):
            stack.append("SQL")
        if any(self.project_path.rglob("*.db")) or any(self.project_path.rglob("*.sqlite*")):
            stack.append("SQLite")
            
        # é…ç½®æ–‡ä»¶
        if (self.project_path / 'docker-compose.yml').exists() or (self.project_path / 'Dockerfile').exists():
            stack.append("Docker")
        if (self.project_path / '.git').exists():
            stack.append("Git")
            
        return stack
    
    def _calculate_project_size(self) -> Dict[str, int]:
        """è®¡ç®—é¡¹ç›®å¤§å°"""
        total_size = 0
        file_count = 0
        
        for root, dirs, files in os.walk(self.project_path):
            # å¿½ç•¥ç‰¹å®šç›®å½•
            dirs[:] = [d for d in dirs if d not in {'.git', '__pycache__', 'node_modules'}]
            
            for file in files:
                try:
                    file_path = os.path.join(root, file)
                    total_size += os.path.getsize(file_path)
                    file_count += 1
                except OSError:
                    pass
        
        return {
            "total_bytes": total_size,
            "total_files": file_count,
            "size_mb": round(total_size / (1024 * 1024), 2)
        }
    
    def generate_byteiq_md(self, output_path: Optional[str] = None) -> str:
        """ç”ŸæˆBYTEIQ.mdé…ç½®æ–‡ä»¶"""
        if not self.analysis_result:
            self.analyze_project()
        
        if output_path is None:
            output_path = self.project_path / "BYTEIQ.md"
        
        content = self._generate_md_content()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"{Fore.GREEN}âœ“ BYTEIQ.md å·²ç”Ÿæˆ: {output_path}{Style.RESET_ALL}")
        return str(output_path)
    
    def _generate_md_content(self) -> str:
        """ç”ŸæˆMarkdownå†…å®¹"""
        info = self.analysis_result["project_info"]
        structure = self.analysis_result["file_structure"]
        features = self.analysis_result["code_features"]
        
        content = f"""# {info['name']} - ByteIQé¡¹ç›®é…ç½®

## é¡¹ç›®ä¿¡æ¯
- **é¡¹ç›®ç±»å‹**: {self.analysis_result['project_type']}
- **æŠ€æœ¯æ ˆ**: {', '.join(self.analysis_result['tech_stack'])}
- **æ–‡ä»¶æ€»æ•°**: {structure['total_files']}
- **é¡¹ç›®å¤§å°**: {info['size']['size_mb']} MB

## AIåŠ©æ‰‹é…ç½®

### é¡¹ç›®ä¸Šä¸‹æ–‡
è¿™æ˜¯ä¸€ä¸ª{self.analysis_result['project_type']}ï¼Œä¸»è¦ä½¿ç”¨{', '.join(self.analysis_result['tech_stack'])}æŠ€æœ¯æ ˆã€‚

### ç¼–ç¨‹è¯­è¨€å’Œæ¡†æ¶
- **ä¸»è¦è¯­è¨€**: {', '.join(features['languages']) if features['languages'] else 'æœªæ£€æµ‹åˆ°'}
- **ä½¿ç”¨æ¡†æ¶**: {', '.join(features['frameworks']) if features['frameworks'] else 'æ— ç‰¹å®šæ¡†æ¶'}
- **ç¼–ç¨‹æ¨¡å¼**: {', '.join(features['patterns']) if features['patterns'] else 'æ ‡å‡†ç¼–ç¨‹'}

### é¡¹ç›®ç»“æ„
```
{self._format_directory_structure()}
```

### AIåŠ©æ‰‹è§„åˆ™

1. **ä»£ç é£æ ¼**
   - éµå¾ªé¡¹ç›®ç°æœ‰çš„ä»£ç é£æ ¼å’Œå‘½åè§„èŒƒ
   - ä¿æŒä»£ç ç®€æ´ã€å¯è¯»æ€§å¼º
   - æ·»åŠ é€‚å½“çš„æ³¨é‡Šå’Œæ–‡æ¡£å­—ç¬¦ä¸²

2. **æŠ€æœ¯è¦æ±‚**
   - ä¼˜å…ˆä½¿ç”¨é¡¹ç›®å·²æœ‰çš„æŠ€æœ¯æ ˆå’Œä¾èµ–
   - ç¡®ä¿æ–°ä»£ç ä¸ç°æœ‰æ¶æ„å…¼å®¹
   - éµå¾ªæœ€ä½³å®è·µå’Œå®‰å…¨è§„èŒƒ

3. **å¼€å‘æµç¨‹**
   - åœ¨ä¿®æ”¹ä»£ç å‰å…ˆç†è§£ç°æœ‰å®ç°
   - æä¾›æ¸…æ™°çš„ä¿®æ”¹è¯´æ˜å’Œç†ç”±
   - è€ƒè™‘å‘åå…¼å®¹æ€§å’Œæ€§èƒ½å½±å“

### ç‰¹æ®Šè¯´æ˜
- è¿™æ˜¯ä¸€ä¸ªAIè¾…åŠ©ç¼–ç¨‹é¡¹ç›®ï¼Œè¯·ç‰¹åˆ«æ³¨æ„ä»£ç çš„å¯ç»´æŠ¤æ€§
- ä¼˜å…ˆè€ƒè™‘ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿç¨³å®šæ€§
- åœ¨å®ç°æ–°åŠŸèƒ½æ—¶ä¿æŒç°æœ‰åŠŸèƒ½çš„å®Œæ•´æ€§

### å¸¸ç”¨å‘½ä»¤å’Œå·¥å…·
- ä¸»è¦å…¥å£æ–‡ä»¶: {', '.join(structure['main_files']) if structure['main_files'] else 'æœªæ£€æµ‹åˆ°'}
- ä¾èµ–ç®¡ç†: {'requirements.txt' if 'requirements.txt' in str(self.analysis_result['dependencies']) else 'å…¶ä»–æ–¹å¼'}

---
*æ­¤é…ç½®æ–‡ä»¶ç”±ByteIQé¡¹ç›®åˆ†æå™¨è‡ªåŠ¨ç”Ÿæˆ*
"""
        return content
    
    def _format_directory_structure(self) -> str:
        """æ ¼å¼åŒ–ç›®å½•ç»“æ„"""
        structure = self.analysis_result["file_structure"]
        dirs = structure["directories"][:10]  # åªæ˜¾ç¤ºå‰10ä¸ªç›®å½•
        
        formatted = f"{self.project_path.name}/\n"
        for directory in sorted(dirs):
            formatted += f"â”œâ”€â”€ {directory}/\n"
        
        if len(structure["directories"]) > 10:
            formatted += f"â””â”€â”€ ... (è¿˜æœ‰ {len(structure['directories']) - 10} ä¸ªç›®å½•)\n"
        
        return formatted

# å…¨å±€é¡¹ç›®åˆ†æå™¨å®ä¾‹
project_analyzer = ProjectAnalyzer()
