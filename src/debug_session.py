"""
AIè¾…åŠ©è°ƒè¯•ä¼šè¯ç®¡ç†å™¨
"""

from colorama import Fore, Style
from .guide_ai import guide_ai
from .ai_client import ai_client
from .ai_tools import ai_tool_processor

class DebugSession:
    """AIè¾…åŠ©è°ƒè¯•ä¼šè¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.is_active = False
        self.bug_description = ""
        self.guide_model = None
        self.session_step = 0
        self.max_steps = 20
        self.shared_context = {
            'project_info': '',
            'analysis_history': [],
            'file_contents': {},
            'executed_commands': [],
            'findings': []
        }
        
    def start_session(self, bug_description, guide_model_name):
        """å¼€å§‹è°ƒè¯•ä¼šè¯"""
        self.is_active = True
        self.bug_description = bug_description
        self.guide_model = guide_model_name
        self.session_step = 0
        
        # è®¾ç½®å¼•å¯¼è€…AIæ¨¡å‹
        guide_ai.set_guide_model(guide_model_name)
        
        print(f"{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}ğŸ”§ AIè¾…åŠ©è°ƒè¯•ä¼šè¯å¯åŠ¨{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}Bugæè¿°: {bug_description[:50]}...{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}å¼•å¯¼è€…AI: {guide_model_name}{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
        
        # è·å–é¡¹ç›®ä¸Šä¸‹æ–‡å¹¶ä¿å­˜åˆ°å…±äº«ä¸Šä¸‹æ–‡
        project_context = self._get_project_context()
        self.shared_context['project_info'] = project_context
        
        # å¼€å§‹å¼•å¯¼
        try:
            guidance = guide_ai.analyze_bug_and_start_guidance(bug_description, project_context)
            
            if not guidance or guidance.startswith("é”™è¯¯ï¼š") or guidance.startswith("å¼•å¯¼è€…AIè°ƒç”¨å¼‚å¸¸"):
                print(f"{Fore.RED}âŒ {guidance or 'å¼•å¯¼è€…AIæ— å“åº”'}{Style.RESET_ALL}")
                self.end_session()
                return False
        except Exception as e:
            print(f"{Fore.RED}âŒ è°ƒè¯•ä¼šè¯åˆå§‹åŒ–å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            self.end_session()
            return False
            
        print(f"\n{Fore.CYAN}ğŸ¤– å¼•å¯¼è€…AI:{Style.RESET_ALL}")
        print(guidance)
        
        # å°†å¼•å¯¼è½¬æ¢ä¸ºä¸»AIå¯ç†è§£çš„æ ¼å¼
        main_ai_prompt = guide_ai.format_guidance_for_main_ai(guidance)
        
        return self._continue_debug_loop(main_ai_prompt)
    
    def _continue_debug_loop(self, prompt):
        """ç»§ç»­è°ƒè¯•å¾ªç¯"""
        while self.is_active and self.session_step < self.max_steps:
            self.session_step += 1
            
            print(f"\n{Fore.YELLOW}ğŸ“ è°ƒè¯•æ­¥éª¤ {self.session_step}/{self.max_steps}{Style.RESET_ALL}")
            print(f"{Fore.CYAN}ä¸»AIæ­£åœ¨åˆ†æ...{Style.RESET_ALL}")
            
            # ä¸»AIå“åº”
            try:
                main_ai_response = ai_client.send_message_streaming(prompt)
                
                if not main_ai_response:
                    print(f"{Fore.RED}âŒ ä¸»AIæ— å“åº”{Style.RESET_ALL}")
                    break
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç³»ç»Ÿé”™è¯¯è€Œéæ­£å¸¸åˆ†æå†…å®¹
                if main_ai_response.startswith("é”™è¯¯ï¼š") or main_ai_response.startswith("APIè°ƒç”¨å¤±è´¥"):
                    print(f"{Fore.RED}âŒ ä¸»AIå“åº”å¼‚å¸¸: {main_ai_response}{Style.RESET_ALL}")
                    break
                    
            except Exception as e:
                print(f"{Fore.RED}âŒ ä¸»AIè°ƒç”¨å¤±è´¥: {str(e)}{Style.RESET_ALL}")
                break
            
            # å¤„ç†ä¸»AIçš„å·¥å…·è°ƒç”¨
            try:
                tool_result = ai_tool_processor.process_response(main_ai_response)
                
                # æ›´æ–°å…±äº«ä¸Šä¸‹æ–‡
                self._update_shared_context_from_tools(tool_result, main_ai_response)
                
                # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†ç»“æŸå¼•å¯¼å·¥å…·
                if tool_result.get('tool_result') and 'GUIDANCE_ENDED_START_FIXING::' in str(tool_result['tool_result']):
                    print(f"{Fore.GREEN}âœ… æ‰§è¡ŒAIå·²å®Œæˆåˆ†æï¼Œå¼€å§‹ä¿®å¤æ¨¡å¼{Style.RESET_ALL}")
                    # æå–åˆ†ææ€»ç»“
                    tool_result_str = str(tool_result['tool_result'])
                    analysis_start = tool_result_str.find('åˆ†ææ€»ç»“: ') + len('åˆ†ææ€»ç»“: ')
                    analysis_end = tool_result_str.find('\n\nç°åœ¨å¼€å§‹è¿›å…¥æ™®é€šAIå¯¹è¯æ¨¡å¼')
                    if analysis_start > len('åˆ†ææ€»ç»“: ') - 1 and analysis_end > analysis_start:
                        analysis_summary = tool_result_str[analysis_start:analysis_end]
                        print(f"\n{Fore.CYAN}ğŸ“‹ åˆ†ææ€»ç»“:{Style.RESET_ALL}")
                        print(analysis_summary)
                        # ä¿å­˜åˆ†ææ€»ç»“åˆ°å…±äº«ä¸Šä¸‹æ–‡
                        self.shared_context['findings'].append({
                            'type': 'final_analysis',
                            'content': analysis_summary,
                            'timestamp': self.session_step
                        })
                    
                    print(f"\n{Fore.MAGENTA}ğŸ”„ åˆ‡æ¢åˆ°æ™®é€šAIå¯¹è¯æ¨¡å¼ï¼Œå¼€å§‹ä¿®å¤bug...{Style.RESET_ALL}")
                    # å°†å…±äº«ä¸Šä¸‹æ–‡ä¼ é€’ç»™ä¸»AI
                    self._transfer_context_to_main_ai()
                    self.end_session()
                    return True
                
                # æ”¶é›†å®Œæ•´çš„ä¸»AIå›ç­”ï¼ˆåŒ…æ‹¬å·¥å…·æ‰§è¡Œç»“æœï¼‰
                full_main_response = main_ai_response
                if tool_result.get('has_tool') and tool_result.get('tool_result'):
                    # æ ¼å¼åŒ–å·¥å…·ç»“æœï¼Œç¡®ä¿å¼•å¯¼è€…AIèƒ½çœ‹åˆ°å®Œæ•´å†…å®¹
                    formatted_tool_result = self._format_tool_result_for_guide(tool_result['tool_result'])
                    full_main_response += f"\n\nå·¥å…·æ‰§è¡Œç»“æœ:\n{formatted_tool_result}"
                    
                    # æ˜¾ç¤ºå·¥å…·æ‰§è¡ŒçŠ¶æ€
                    if tool_result.get('executed_tools'):
                        executed_tools_str = ', '.join(tool_result['executed_tools'])
                        print(f"{Fore.GREEN}âœ“ å·¥å…·æ‰§è¡Œå®Œæˆ: {executed_tools_str}{Style.RESET_ALL}")
                        
            except Exception as e:
                print(f"{Fore.YELLOW}âš ï¸ å·¥å…·å¤„ç†å¼‚å¸¸: {str(e)}{Style.RESET_ALL}")
                full_main_response = main_ai_response  # ä½¿ç”¨åŸå§‹å“åº”
            
            # å¼•å¯¼è€…AIç»§ç»­å¼•å¯¼
            print(f"\n{Fore.CYAN}ğŸ¤– å¼•å¯¼è€…AIåˆ†æä¸»AIå›ç­”...{Style.RESET_ALL}")
            try:
                # å°†å…±äº«ä¸Šä¸‹æ–‡ä¼ é€’ç»™å¼•å¯¼è€…AI
                context_enhanced_response = self._enhance_response_with_context(full_main_response)
                guidance = guide_ai.continue_guidance(context_enhanced_response)
                
                # è®°å½•å¼•å¯¼è€…çš„åˆ†æåˆ°å…±äº«ä¸Šä¸‹æ–‡
                self.shared_context['analysis_history'].append({
                    'step': self.session_step,
                    'guidance': guidance,
                    'main_ai_response': main_ai_response
                })
                
                # æ”¹è¿›é”™è¯¯å¤„ç† - ä¸å› ä¸ºå¼•å¯¼è€…AIçš„åˆ†æå†…å®¹åŒ…å«"é”™è¯¯"å°±ç»ˆæ­¢ä¼šè¯
                if not guidance or guidance.startswith("é”™è¯¯ï¼š") or guidance.startswith("å¼•å¯¼è€…AIè°ƒç”¨å¼‚å¸¸"):
                    print(f"{Fore.RED}âŒ å¼•å¯¼è€…AIå¼‚å¸¸: {guidance or 'æ— å“åº”'}{Style.RESET_ALL}")
                    break
                    
            except Exception as e:
                print(f"{Fore.RED}âŒ å¼•å¯¼è€…AIè°ƒç”¨å¤±è´¥: {str(e)}{Style.RESET_ALL}")
                break
            
            # æ£€æŸ¥æ˜¯å¦è°ƒè¯•å®Œæˆ
            if guide_ai.is_debugging_complete(guidance):
                print(f"\n{Fore.GREEN}âœ… è°ƒè¯•å®Œæˆï¼{Style.RESET_ALL}")
                self.end_session()
                return True
            
            # å‡†å¤‡ä¸‹ä¸€è½®å¯¹è¯
            prompt = guide_ai.format_guidance_for_main_ai(guidance)
        
        if self.session_step >= self.max_steps:
            print(f"\n{Fore.YELLOW}âš ï¸ å·²è¾¾åˆ°æœ€å¤§è°ƒè¯•æ­¥éª¤æ•°ï¼Œä¼šè¯ç»“æŸ{Style.RESET_ALL}")
        
        self.end_session()
        return False
    
    def _get_project_context(self):
        """è·å–é¡¹ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        try:
            import os
            context = f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\n"
            
            # è·å–é¡¹ç›®ç»“æ„
            structure = ai_client.get_project_structure(max_depth=2)
            if structure:
                context += f"é¡¹ç›®ç»“æ„:\n{structure}"
            
            return context
        except Exception as e:
            return f"æ— æ³•è·å–é¡¹ç›®ä¸Šä¸‹æ–‡: {str(e)}"
    
    def end_session(self):
        """ç»“æŸè°ƒè¯•ä¼šè¯"""
        if self.is_active:
            self.is_active = False
            guide_ai.clear_session()
            print(f"\n{Fore.MAGENTA}ğŸ”§ AIè¾…åŠ©è°ƒè¯•ä¼šè¯å·²ç»“æŸ{Style.RESET_ALL}")
    
    def get_session_status(self):
        """è·å–ä¼šè¯çŠ¶æ€"""
        if not self.is_active:
            return "æ— æ´»åŠ¨è°ƒè¯•ä¼šè¯"
        
        return f"""
å½“å‰è°ƒè¯•ä¼šè¯çŠ¶æ€:
- Bugæè¿°: {self.bug_description[:50]}...
- å¼•å¯¼è€…AI: {self.guide_model}
- å½“å‰æ­¥éª¤: {self.session_step}/{self.max_steps}
- ä¼šè¯çŠ¶æ€: æ´»åŠ¨ä¸­
"""

    def _format_tool_result_for_guide(self, tool_result):
        """æ ¼å¼åŒ–å·¥å…·ç»“æœï¼Œç¡®ä¿å¼•å¯¼è€…AIèƒ½è·å–å®Œæ•´ä¿¡æ¯"""
        import json
        
        # å¦‚æœå·¥å…·ç»“æœæ˜¯å­—å…¸ï¼ˆåŒ…å«è¯¦ç»†ä¿¡æ¯ï¼‰ï¼Œæå–å®Œæ•´å†…å®¹
        if isinstance(tool_result, dict):
            if tool_result.get('status') == 'success' and 'content' in tool_result:
                # å¯¹äºæ–‡ä»¶è¯»å–ç»“æœï¼ŒåŒ…å«å®Œæ•´æ–‡ä»¶å†…å®¹
                formatted_result = f"""
æ–‡ä»¶è·¯å¾„: {tool_result.get('file_path', 'æœªçŸ¥')}
è¡Œæ•°: {tool_result.get('line_count', 0)}
å­—ç¬¦æ•°: {tool_result.get('char_count', 0)}
æ–‡ä»¶å†…å®¹:
{tool_result['content']}
"""
                return formatted_result
            else:
                # å…¶ä»–å­—å…¸ç»“æœï¼Œè½¬æ¢ä¸ºJSONæ ¼å¼
                return json.dumps(tool_result, ensure_ascii=False, indent=2)
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        return str(tool_result)

    def _update_shared_context_from_tools(self, tool_result, main_ai_response):
        """ä»å·¥å…·æ‰§è¡Œç»“æœæ›´æ–°å…±äº«ä¸Šä¸‹æ–‡"""
        try:
            if not tool_result.get('has_tool'):
                return
            
            executed_tools = tool_result.get('executed_tools', [])
            tool_result_content = tool_result.get('tool_result', '')
            
            # è®°å½•æ‰§è¡Œçš„å·¥å…·
            for tool_name in executed_tools:
                self.shared_context['executed_commands'].append({
                    'step': self.session_step,
                    'tool': tool_name,
                    'result': tool_result_content
                })
            
            # å¦‚æœæ˜¯æ–‡ä»¶è¯»å–å·¥å…·ï¼Œä¿å­˜æ–‡ä»¶å†…å®¹
            if 'read_file' in executed_tools and isinstance(tool_result_content, str):
                # å°è¯•æå–æ–‡ä»¶è·¯å¾„å’Œå†…å®¹
                import re
                file_match = re.search(r'<read_file><path>(.*?)</path></read_file>', main_ai_response)
                if file_match:
                    file_path = file_match.group(1)
                    self.shared_context['file_contents'][file_path] = tool_result_content
            
            # è®°å½•é‡è¦å‘ç°
            if any(keyword in tool_result_content.lower() for keyword in ['é”™è¯¯', 'error', 'é—®é¢˜', 'bug', 'å¼‚å¸¸']):
                self.shared_context['findings'].append({
                    'type': 'issue_found',
                    'content': tool_result_content[:500],  # é™åˆ¶é•¿åº¦
                    'step': self.session_step,
                    'tools_used': executed_tools
                })
                
        except Exception as e:
            print(f"{Fore.YELLOW}âš ï¸ æ›´æ–°å…±äº«ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}{Style.RESET_ALL}")

    def _enhance_response_with_context(self, response):
        """ç”¨å…±äº«ä¸Šä¸‹æ–‡å¢å¼ºå“åº”"""
        try:
            context_summary = self._get_context_summary()
            if context_summary:
                enhanced_response = f"""
{response}

=== å…±äº«ä¸Šä¸‹æ–‡ä¿¡æ¯ ===
{context_summary}
=== ä¸Šä¸‹æ–‡ä¿¡æ¯ç»“æŸ ===
"""
                return enhanced_response
            return response
        except Exception as e:
            print(f"{Fore.YELLOW}âš ï¸ å¢å¼ºä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            return response

    def _get_context_summary(self):
        """è·å–å…±äº«ä¸Šä¸‹æ–‡æ‘˜è¦"""
        try:
            summary_parts = []
            
            # é¡¹ç›®ä¿¡æ¯
            if self.shared_context['project_info']:
                summary_parts.append(f"é¡¹ç›®ä¿¡æ¯:\n{self.shared_context['project_info'][:300]}...")
            
            # å·²è¯»å–çš„æ–‡ä»¶
            if self.shared_context['file_contents']:
                file_list = list(self.shared_context['file_contents'].keys())
                summary_parts.append(f"å·²åˆ†ææ–‡ä»¶: {', '.join(file_list[:5])}")
            
            # æ‰§è¡Œçš„å‘½ä»¤
            if self.shared_context['executed_commands']:
                recent_commands = self.shared_context['executed_commands'][-3:]
                cmd_summary = [f"{cmd['tool']}" for cmd in recent_commands]
                summary_parts.append(f"æœ€è¿‘æ‰§è¡Œå·¥å…·: {', '.join(cmd_summary)}")
            
            # é‡è¦å‘ç°
            if self.shared_context['findings']:
                findings_count = len(self.shared_context['findings'])
                summary_parts.append(f"å‘ç°é—®é¢˜æ•°é‡: {findings_count}")
                if findings_count > 0:
                    latest_finding = self.shared_context['findings'][-1]
                    summary_parts.append(f"æœ€æ–°å‘ç°: {latest_finding['content'][:200]}...")
            
            return '\n'.join(summary_parts) if summary_parts else ""
            
        except Exception as e:
            return f"ä¸Šä¸‹æ–‡æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"

    def _transfer_context_to_main_ai(self):
        """å°†å…±äº«ä¸Šä¸‹æ–‡ä¼ é€’ç»™ä¸»AI"""
        try:
            from .ai_client import ai_client
            
            # æ„å»ºä¸Šä¸‹æ–‡æ€»ç»“
            context_message = f"""
=== è°ƒè¯•ä¼šè¯ä¸Šä¸‹æ–‡ä¼ é€’ ===
Bugæè¿°: {self.bug_description}
è°ƒè¯•æ­¥éª¤: {self.session_step}

é¡¹ç›®ä¿¡æ¯:
{self.shared_context['project_info']}

å·²åˆ†ææ–‡ä»¶:
{chr(10).join([f"- {path}: {content[:100]}..." for path, content in self.shared_context['file_contents'].items()])}

é‡è¦å‘ç°:
{chr(10).join([f"- æ­¥éª¤{f['step']}: {f['content'][:200]}..." for f in self.shared_context['findings']])}

æ‰§è¡Œçš„å·¥å…·:
{chr(10).join([f"- æ­¥éª¤{cmd['step']}: {cmd['tool']}" for cmd in self.shared_context['executed_commands']])}

ç°åœ¨è¯·åŸºäºä»¥ä¸Šåˆ†æå¼€å§‹ä¿®å¤bugã€‚
=== ä¸Šä¸‹æ–‡ä¼ é€’ç»“æŸ ===
"""
            
            # å°†ä¸Šä¸‹æ–‡æ·»åŠ åˆ°AIå®¢æˆ·ç«¯çš„ä¸Šä¸‹æ–‡ä¸­
            ai_client.add_context_message("è°ƒè¯•ä¼šè¯ä¸Šä¸‹æ–‡", context_message)
            
            print(f"{Fore.GREEN}âœ“ å…±äº«ä¸Šä¸‹æ–‡å·²ä¼ é€’ç»™ä¸»AI{Style.RESET_ALL}")
            
        except Exception as e:
            print(f"{Fore.YELLOW}âš ï¸ ä¸Šä¸‹æ–‡ä¼ é€’å¤±è´¥: {str(e)}{Style.RESET_ALL}")

# å…¨å±€è°ƒè¯•ä¼šè¯å®ä¾‹
debug_session = DebugSession()
