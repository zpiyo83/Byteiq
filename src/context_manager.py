"""
æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿ - å……åˆ†åˆ©ç”¨Claudeçš„200K tokenä¸Šä¸‹æ–‡çª—å£
"""

import json
import time
import tiktoken
from typing import List, Dict, Any, Optional
from pathlib import Path
from colorama import Fore, Style

class ContextManager:
    """æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self, max_tokens=None):  # ç”¨æˆ·å¯é…ç½®çš„ä¸Šä¸‹æ–‡é™åˆ¶
        # ä»é…ç½®æ–‡ä»¶åŠ è½½max_tokensè®¾ç½®
        if max_tokens is None:
            from .config import load_config
            config = load_config()
            max_tokens = config.get('max_tokens', 12800)
        self.max_tokens = max_tokens
        self.conversation_history = []
        self.project_context = {}
        self.code_context = {}
        self.session_summary = ""
        self.encoding = tiktoken.get_encoding("cl100k_base")  # Claudeä½¿ç”¨çš„ç¼–ç 
        
    def count_tokens(self, text: str) -> int:
        """è®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
        try:
            return len(self.encoding.encode(text))
        except:
            # å¦‚æœç¼–ç å¤±è´¥ï¼Œä½¿ç”¨è¿‘ä¼¼è®¡ç®—
            return len(text) // 3
    
    def add_message(self, role: str, content: str, metadata: Optional[Dict] = None):
        """æ·»åŠ æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡"""
        message = {
            "role": role,
            "content": content,
            "timestamp": time.time(),
            "tokens": self.count_tokens(content),
            "metadata": metadata or {}
        }
        
        # å¦‚æœæ˜¯ç”¨æˆ·çš„åŸå§‹éœ€æ±‚ï¼Œæ ‡è®°ä¸ºé«˜ä¼˜å…ˆçº§
        if role == "user" and not self.conversation_history:
            self.add_project_context("original_request", content, "critical")
        
        self.conversation_history.append(message)
        self._optimize_context()
    
    def _optimize_context(self):
        """ä¼˜åŒ–ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿ä¸è¶…è¿‡tokené™åˆ¶"""
        total_tokens = self._calculate_total_tokens()
        
        if total_tokens <= self.max_tokens:
            return
        
        # æ‰§è¡Œä¸Šä¸‹æ–‡å‹ç¼©ç­–ç•¥
        self._compress_context()
        
        # æ¸…ç†è¿‡æœŸçš„ä»£ç ä¸Šä¸‹æ–‡
        self._cleanup_code_context()
    
    def _calculate_total_tokens(self) -> int:
        """è®¡ç®—å½“å‰æ€»tokenæ•°"""
        total = 0
        
        # è®¡ç®—å¯¹è¯å†å²
        for msg in self.conversation_history:
            total += msg.get("tokens", 0)
        
        # è®¡ç®—é¡¹ç›®ä¸Šä¸‹æ–‡
        for context in self.project_context.values():
            total += self.count_tokens(str(context))
        
        # è®¡ç®—ä»£ç ä¸Šä¸‹æ–‡
        for context in self.code_context.values():
            total += self.count_tokens(str(context))
        
        # è®¡ç®—ä¼šè¯æ‘˜è¦
        if self.session_summary:
            total += self.count_tokens(self.session_summary)
        
        return total
    
    def _compress_context(self):
        """å‹ç¼©ä¸Šä¸‹æ–‡"""
        print(f"{Fore.YELLOW}ğŸ”„ ä¸Šä¸‹æ–‡æ¥è¿‘é™åˆ¶ï¼Œæ­£åœ¨æ™ºèƒ½å‹ç¼©...{Style.RESET_ALL}")
        
        # 1. ä¿ç•™æœ€è¿‘çš„é‡è¦æ¶ˆæ¯
        important_messages = self._extract_important_messages()
        
        # 2. ç”Ÿæˆä¼šè¯æ‘˜è¦
        old_messages = [msg for msg in self.conversation_history if msg not in important_messages]
        if old_messages:
            self.session_summary = self._generate_session_summary(old_messages)
        
        # 3. æ›´æ–°å¯¹è¯å†å²
        self.conversation_history = important_messages
        
        # 4. æ¸…ç†è¿‡æœŸçš„ä»£ç ä¸Šä¸‹æ–‡
        self._cleanup_code_context()
        
        print(f"{Fore.GREEN}âœ“ ä¸Šä¸‹æ–‡å‹ç¼©å®Œæˆ{Style.RESET_ALL}")
    
    def _extract_important_messages(self) -> List[Dict]:
        """æå–é‡è¦æ¶ˆæ¯"""
        important = []
        
        # ä¿ç•™æœ€è¿‘çš„20æ¡æ¶ˆæ¯
        recent_messages = self.conversation_history[-20:]
        
        # ä¿ç•™åŒ…å«å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯
        tool_messages = [msg for msg in self.conversation_history 
                        if any(tag in msg["content"] for tag in ["<", ">", "å·¥å…·", "æ‰§è¡Œ"])]
        
        # ä¿ç•™é”™è¯¯å’Œé‡è¦ä¿¡æ¯
        error_messages = [msg for msg in self.conversation_history 
                         if any(keyword in msg["content"].lower() 
                               for keyword in ["é”™è¯¯", "error", "å¤±è´¥", "æˆåŠŸ", "å®Œæˆ"])]
        
        # åˆå¹¶å¹¶å»é‡
        all_important = recent_messages + tool_messages[-10:] + error_messages[-5:]
        seen = set()
        for msg in all_important:
            msg_id = (msg["role"], msg["content"][:100], msg["timestamp"])
            if msg_id not in seen:
                important.append(msg)
                seen.add(msg_id)
        
        # æŒ‰æ—¶é—´æ’åº
        important.sort(key=lambda x: x["timestamp"])
        
        return important
    
    def _generate_session_summary(self, messages: List[Dict]) -> str:
        """ç”Ÿæˆä¼šè¯æ‘˜è¦"""
        if not messages:
            return self.session_summary
        
        # æå–å…³é”®ä¿¡æ¯
        user_requests = [msg["content"] for msg in messages if msg["role"] == "user"]
        ai_actions = [msg["content"] for msg in messages if msg["role"] == "assistant"]
        
        summary_parts = []
        
        if self.session_summary:
            summary_parts.append(f"ä¹‹å‰çš„ä¼šè¯æ‘˜è¦: {self.session_summary}")
        
        if user_requests:
            summary_parts.append(f"ç”¨æˆ·è¯·æ±‚: {'; '.join(user_requests[-5:])}")
        
        if ai_actions:
            # æå–å·¥å…·è°ƒç”¨å’Œé‡è¦æ“ä½œ
            actions = []
            for action in ai_actions[-10:]:
                if any(tag in action for tag in ["åˆ›å»º", "ä¿®æ”¹", "æ‰§è¡Œ", "å®Œæˆ"]):
                    actions.append(action[:100])
            if actions:
                summary_parts.append(f"æ‰§è¡Œçš„æ“ä½œ: {'; '.join(actions)}")
        
        return " | ".join(summary_parts)
    
    def _cleanup_code_context(self):
        """æ¸…ç†è¿‡æœŸçš„ä»£ç ä¸Šä¸‹æ–‡"""
        current_time = time.time()
        
        # ç§»é™¤è¶…è¿‡1å°æ—¶çš„ä»£ç ä¸Šä¸‹æ–‡
        expired_keys = []
        for key, context in self.code_context.items():
            if current_time - context.get("timestamp", 0) > 3600:
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.code_context[key]
    
    def add_project_context(self, key: str, content: str, priority: str = "normal"):
        """æ·»åŠ é¡¹ç›®ä¸Šä¸‹æ–‡"""
        self.project_context[key] = {
            "content": content,
            "priority": priority,  # critical > high > normal
            "timestamp": time.time(),
            "tokens": self.count_tokens(content)
        }
    
    def _get_todo_context(self) -> str:
        """è·å–å½“å‰TODOä»»åŠ¡ä¸Šä¸‹æ–‡"""
        try:
            import os
            todo_file = "todo_data.json"
            if os.path.exists(todo_file):
                import json
                with open(todo_file, 'r', encoding='utf-8') as f:
                    todos = json.load(f)
                
                active_todos = []
                for todo in todos:
                    if todo.get('status') in ['pending', 'in_progress']:
                        priority_mark = "ğŸ”¥" if todo.get('priority') == 'high' else "ğŸ“‹"
                        status_mark = "â³" if todo.get('status') == 'in_progress' else "ğŸ“"
                        active_todos.append(f"{priority_mark}{status_mark} {todo.get('content', '')}")
                
                if active_todos:
                    return "; ".join(active_todos[:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ªä»»åŠ¡
        except:
            pass
        return ""
    
    def add_code_context(self, file_path: str, content: str, context_type: str = "file"):
        """æ·»åŠ ä»£ç ä¸Šä¸‹æ–‡"""
        self.code_context[file_path] = {
            "content": content,
            "type": context_type,
            "timestamp": time.time(),
            "tokens": self.count_tokens(content)
        }
    
    def update_todo_context(self):
        """æ›´æ–°TODOä¸Šä¸‹æ–‡åˆ°é¡¹ç›®ä¸Šä¸‹æ–‡ä¸­"""
        todo_context = self._get_todo_context()
        if todo_context:
            self.add_project_context("current_todos", todo_context, "high")
    
    def get_context_for_ai(self) -> Dict[str, Any]:
        """è·å–ç”¨äºAIçš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context = {
            "conversation_history": [
                {"role": msg["role"], "content": msg["content"]} 
                for msg in self.conversation_history
            ],
            "session_summary": self.session_summary,
            "project_context": {},
            "code_context": {},
            "stats": {
                "total_tokens": self._calculate_total_tokens(),
                "max_tokens": self.max_tokens,
                "utilization": f"{(self._calculate_total_tokens() / self.max_tokens * 100):.1f}%"
            }
        }
        
        # æ·»åŠ é«˜ä¼˜å…ˆçº§é¡¹ç›®ä¸Šä¸‹æ–‡
        for key, ctx in self.project_context.items():
            if ctx["priority"] == "high" or len(context["project_context"]) < 5:
                context["project_context"][key] = ctx["content"]
        
        # æ·»åŠ æœ€è¿‘çš„ä»£ç ä¸Šä¸‹æ–‡
        recent_code = sorted(
            self.code_context.items(),
            key=lambda x: x[1]["timestamp"],
            reverse=True
        )[:10]
        
        for file_path, ctx in recent_code:
            context["code_context"][file_path] = {
                "type": ctx["type"],
                "content": ctx["content"][:2000]  # é™åˆ¶é•¿åº¦
            }
        
        return context
    
    def get_enhanced_messages(self) -> List[Dict[str, str]]:
        """è·å–å¢å¼ºçš„æ¶ˆæ¯åˆ—è¡¨ï¼ŒæŒ‰é‡è¦æ€§æ’åºï¼Œä¸åŒ…å«ç³»ç»Ÿæç¤ºè¯"""
        messages = []
        
        # 1. æœ€é«˜ä¼˜å…ˆçº§ï¼šåŸå§‹éœ€æ±‚å’Œå…³é”®è®¡åˆ’
        critical_contexts = []
        high_contexts = []
        normal_contexts = []
        
        for key, ctx in self.project_context.items():
            if ctx["priority"] == "critical":
                critical_contexts.append(f"{key}: {ctx['content']}")
            elif ctx["priority"] == "high":
                high_contexts.append(f"{key}: {ctx['content']}")
            else:
                normal_contexts.append(f"{key}: {ctx['content']}")
        
        # æŒ‰ä¼˜å…ˆçº§æ·»åŠ ä¸Šä¸‹æ–‡
        if critical_contexts:
            messages.append({
                "role": "system",
                "content": f"[å…³é”®ä¿¡æ¯] {'; '.join(critical_contexts)}"
            })
        
        if high_contexts:
            messages.append({
                "role": "system", 
                "content": f"[é‡è¦ä¸Šä¸‹æ–‡] {'; '.join(high_contexts)}"
            })
        
        # 2. æ·»åŠ TODOä»»åŠ¡ä¸Šä¸‹æ–‡
        todo_context = self._get_todo_context()
        if todo_context:
            messages.append({
                "role": "system",
                "content": f"[å½“å‰ä»»åŠ¡] {todo_context}"
            })
        
        # 3. æ·»åŠ ä¼šè¯æ‘˜è¦
        if self.session_summary:
            messages.append({
                "role": "system",
                "content": f"[ä¼šè¯æ‘˜è¦] {self.session_summary}"
            })
        
        # 4. æ·»åŠ å¯¹è¯å†å²ï¼Œä½†è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯é¿å…é‡å¤
        for msg in self.conversation_history:
            if msg["role"] != "system":
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
        
        return messages
    
    def save_context(self, file_path: str = ".byteiq_context.json"):
        """ä¿å­˜ä¸Šä¸‹æ–‡åˆ°æ–‡ä»¶"""
        try:
            context_data = {
                "conversation_history": self.conversation_history,
                "project_context": self.project_context,
                "session_summary": self.session_summary,
                "timestamp": time.time()
            }
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(context_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            print(f"{Fore.YELLOW}ä¿å­˜ä¸Šä¸‹æ–‡å¤±è´¥: {e}{Style.RESET_ALL}")
    
    def load_context(self, file_path: str = ".byteiq_context.json"):
        """ä»æ–‡ä»¶åŠ è½½ä¸Šä¸‹æ–‡"""
        try:
            if not Path(file_path).exists():
                return False
            
            with open(file_path, 'r', encoding='utf-8') as f:
                context_data = json.load(f)
            
            self.conversation_history = context_data.get("conversation_history", [])
            self.project_context = context_data.get("project_context", {})
            self.session_summary = context_data.get("session_summary", "")
            
            # é‡æ–°è®¡ç®—tokenæ•°
            for msg in self.conversation_history:
                if "tokens" not in msg:
                    msg["tokens"] = self.count_tokens(msg["content"])
            
            print(f"{Fore.GREEN}âœ“ å·²åŠ è½½ä¸Šä¸‹æ–‡å†å²{Style.RESET_ALL}")
            return True
            
        except Exception as e:
            print(f"{Fore.YELLOW}åŠ è½½ä¸Šä¸‹æ–‡å¤±è´¥: {e}{Style.RESET_ALL}")
            return False
    
    def clear_context(self):
        """æ¸…é™¤æ‰€æœ‰ä¸Šä¸‹æ–‡"""
        self.conversation_history = []
        self.project_context = {}
        self.code_context = {}
        self.session_summary = ""
        print(f"{Fore.GREEN}âœ“ å·²æ¸…é™¤æ‰€æœ‰ä¸Šä¸‹æ–‡{Style.RESET_ALL}")
    
    def get_context_stats(self) -> Dict[str, Any]:
        """è·å–ä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯"""
        total_tokens = self._calculate_total_tokens()
        
        return {
            "total_tokens": total_tokens,
            "max_tokens": self.max_tokens,
            "utilization_percent": round((total_tokens / self.max_tokens) * 100, 1),
            "conversation_messages": len(self.conversation_history),
            "project_contexts": len(self.project_context),
            "code_contexts": len(self.code_context),
            "has_summary": bool(self.session_summary)
        }
    
    def set_max_tokens(self, max_tokens: int):
        """è®¾ç½®æœ€å¤§tokenæ•°"""
        if max_tokens < 1000:
            raise ValueError("æœ€å¤§tokenæ•°ä¸èƒ½å°‘äº1000")
        if max_tokens > 200000:
            raise ValueError("æœ€å¤§tokenæ•°ä¸èƒ½è¶…è¿‡200000")
        
        self.max_tokens = max_tokens
        
        # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
        from .config import load_config, save_config
        config = load_config()
        config['max_tokens'] = max_tokens
        save_config(config)
        
        print(f"{Fore.GREEN}âœ“ ä¸Šä¸‹æ–‡é™åˆ¶å·²è®¾ç½®ä¸º {max_tokens:,} tokens{Style.RESET_ALL}")
        
        # å¦‚æœå½“å‰ä¸Šä¸‹æ–‡è¶…å‡ºé™åˆ¶ï¼Œè§¦å‘å‹ç¼©
        if self._calculate_total_tokens() > max_tokens:
            self._optimize_context()

# å…¨å±€ä¸Šä¸‹æ–‡ç®¡ç†å™¨å®ä¾‹
context_manager = ContextManager()
